{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a328fc-a255-4bba-b0a9-a3beac21ebc6",
   "metadata": {},
   "source": [
    "<div style=\"color:white; background-color:#263b52; text-align:center; padding: 25px 0;\">\n",
    "    <div style=\"font-size:34px; font-family:calibri; font-weight:bold;\">\n",
    "        ML Zoomcamp 2025\n",
    "    </div>\n",
    "    <div style=\"font-size:22px; font-family:verdana; line-height: 1.5; margin-top:10px;\">\n",
    "        Homework 3: Machine Learning for Classification\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-top:20px; overflow:auto;\">\n",
    "  <div style=\"float:left; width:50%; text-align:left; font-family:verdana; font-size:16px; color:#263b52;\">\n",
    "      <p style=\"margin:4px 0;\"><b>Author:</b> CGD</p>\n",
    "      <p style=\"margin:4px 0;\"><b>GitHub:</b> <a href=\"https://github.com/CGD2401\" target=\"_blank\">CGD2401</a></p>\n",
    "      <p style=\"margin:4px 0;\"><b>Date:</b> October 2025</p>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"float:right; width:50%; text-align:right; font-family:verdana; font-size:16px; color:#263b52;\">\n",
    "      <p style=\"margin:4px 0;\">Notebook prepared for</p>\n",
    "      <p style=\"margin:4px 0;\"><b>Machine Learning Zoomcamp</b></p>\n",
    "      <p style=\"margin:4px 0;\">Homework covering Q1–Q6</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"width:100%; clear:both;\"></div>\n",
    "\n",
    "<hr style=\"border:3px solid #7ba5b0; margin-top:25px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ae5e9",
   "metadata": {},
   "source": [
    "## 1. Importing libraries\n",
    "\n",
    "In this section, we load the essential Python libraries required for the homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01a3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mutual_info_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb5997",
   "metadata": {},
   "source": [
    "## 2. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce89e2",
   "metadata": {},
   "source": [
    "\n",
    "Dataset link from the homework:\n",
    "\n",
    "\n",
    "```\n",
    "https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80641ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded remote CSV: https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_URL = os.environ.get(\n",
    "    \"MLZ_HW3_DATA_URL\",\n",
    "    \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    ")\n",
    "\n",
    "def load_data(src: str) -> pd.DataFrame:\n",
    "    if src.startswith(\"http\"):\n",
    "        try:\n",
    "            df = pd.read_csv(src)\n",
    "            print(f\"Loaded remote CSV: {src}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Remote load failed: {e}\")\n",
    "            print(\"If you're offline, download the file manually and set DATA_URL to its local path.\")\n",
    "    # Local fallback\n",
    "    if Path(src).exists():\n",
    "        df = pd.read_csv(src)\n",
    "        print(f\"Loaded local CSV: {src}\")\n",
    "        return df\n",
    "    raise FileNotFoundError(f\"Could not load data from {src}.\")\n",
    "\n",
    "df = load_data(DATA_URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac25b1",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0667e",
   "metadata": {},
   "source": [
    "\n",
    "- Ensure lowercase snake_case column names\n",
    "\"\n",
    "- Replace missing values as required:\n",
    "\"\n",
    "  - **Categorical** → `'NA'`\n",
    "\"\n",
    "  - **Numerical** → `0.0`\n",
    "\"\n",
    "- Target is `converted` (binary).\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d2a1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry employment_status       location  \\\n",
       "0      paid_ads          NA        unemployed  south_america   \n",
       "1  social_media      retail          employed  south_america   \n",
       "2        events  healthcare        unemployed      australia   \n",
       "3      paid_ads      retail                NA      australia   \n",
       "4      referral   education     self_employed         europe   \n",
       "\n",
       "   number_of_courses_viewed  annual_income  interaction_count  lead_score  \\\n",
       "0                         1        79450.0                  4        0.94   \n",
       "1                         1        46992.0                  1        0.80   \n",
       "2                         5        78796.0                  3        0.69   \n",
       "3                         2        83843.0                  1        0.87   \n",
       "4                         3        85012.0                  3        0.62   \n",
       "\n",
       "   converted  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize column names\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "# Identify columns by dtype\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[np.number, \"float\", \"int\"]).columns.tolist()\n",
    "\n",
    "# Convert obvious numeric cols that might be read as object\n",
    "possible_num = [\"number_of_courses_viewed\", \"annual_income\", \"interaction_count\", \"lead_score\", \"converted\"]\n",
    "for c in possible_num:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Recompute dtypes after coercion\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "num_cols = [c for c in df.columns if c not in cat_cols]\n",
    "\n",
    "# Missing values handling\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "    df[c] = df[c].fillna(\"NA\").replace({\"nan\": \"NA\", \"\": \"NA\"})\n",
    "\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Ensure target int\n",
    "if \"converted\" in df.columns:\n",
    "    df[\"converted\"] = df[\"converted\"].astype(int)\n",
    "\n",
    "df[cat_cols + [c for c in [\"number_of_courses_viewed\",\"annual_income\",\"interaction_count\",\"lead_score\",\"converted\"] if c in df.columns]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fec8e",
   "metadata": {},
   "source": [
    "## 4. Homework Questions\n",
    "\n",
    "### Q1 — Mode for `industry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3163c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_mode = df[\"industry\"].mode(dropna=False)[0] if \"industry\" in df.columns else \"NA\"\n",
    "q1_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce84508",
   "metadata": {},
   "source": [
    "### Q2 — Biggest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ba4284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annual_income & interaction_count', 0.027036472404814257),\n",
       " ('number_of_courses_viewed & interaction_count', 0.023565222882888096),\n",
       " ('interaction_count & lead_score', 0.009888182496913091),\n",
       " ('number_of_courses_viewed & lead_score', 0.004878998354681237)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_corr(a: str, b: str) -> float:\n",
    "    s = df[[a, b]].copy()\n",
    "    s = s.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return s[a].corr(s[b]) if len(s) > 1 else np.nan\n",
    "\n",
    "pairs = [\n",
    "    (\"interaction_count\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"interaction_count\"),\n",
    "    (\"annual_income\", \"interaction_count\"),\n",
    "]\n",
    "\n",
    "corrs = {}\n",
    "for a, b in pairs:\n",
    "    if a in df.columns and b in df.columns:\n",
    "        corrs[f\"{a} & {b}\"] = abs(pair_corr(a, b))\n",
    "    else:\n",
    "        corrs[f\"{a} & {b}\"] = np.nan\n",
    "\n",
    "sorted_corrs = sorted(corrs.items(), key=lambda kv: (np.nan_to_num(kv[1], nan=-1), kv[0]), reverse=True)\n",
    "sorted_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd6ac8",
   "metadata": {},
   "source": [
    "### Train/Validation/Test split (60/20/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60710052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 293, 293, 0.6190150478796169)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove target from features for splitting\n",
    "if \"converted\" not in df.columns:\n",
    "    raise ValueError(\"Target column 'converted' not found.\")\n",
    "\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df[\"converted\"])\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=SEED, stratify=df_train_full[\"converted\"])  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "len(df_train), len(df_val), len(df_test), df['converted'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef757a7",
   "metadata": {},
   "source": [
    "### Q3 — Biggest MI - Mutual Information (train only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ea87bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lead_source', 0.028),\n",
       " ('employment_status', 0.008),\n",
       " ('industry', 0.006),\n",
       " ('location', 0.001)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [\"industry\", \"location\", \"lead_source\", \"employment_status\"]\n",
    "categorical = [c for c in categorical if c in df_train.columns]\n",
    "\n",
    "def mi_cat(x: pd.Series, y: pd.Series) -> float:\n",
    "    xi = x.astype(\"category\").cat.codes\n",
    "    return mutual_info_score(xi, y)\n",
    "\n",
    "y_train = df_train[\"converted\"]\n",
    "mi_scores = {}\n",
    "for c in categorical:\n",
    "    mi = mi_cat(df_train[c], y_train)\n",
    "    mi_scores[c] = round(mi, 3)\n",
    "\n",
    "sorted_mi = sorted(mi_scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "sorted_mi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbbf2d",
   "metadata": {},
   "source": [
    "### Modeling helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc976cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_vectorize(frame: pd.DataFrame, feature_cols: List[str]) -> Tuple[np.ndarray, DictVectorizer]:\n",
    "    records = frame[feature_cols].to_dict(orient=\"records\")\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X = dv.fit_transform(records)\n",
    "    return X, dv\n",
    "\n",
    "def dict_transform(frame: pd.DataFrame, dv: DictVectorizer, feature_cols: List[str]) -> np.ndarray:\n",
    "    return dv.transform(frame[feature_cols].to_dict(orient=\"records\"))\n",
    "\n",
    "def train_logreg(train_df: pd.DataFrame, val_df: pd.DataFrame, feature_cols: List[str], C=1.0, solver=\"liblinear\", random_state=42):\n",
    "    X_train, dv = dict_vectorize(train_df, feature_cols)\n",
    "    y_train = train_df[\"converted\"].values\n",
    "    model = LogisticRegression(solver=solver, C=C, max_iter=1000, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    X_val = dict_transform(val_df, dv, feature_cols)\n",
    "    y_val = val_df[\"converted\"].values\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    return acc, model, dv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fa60d",
   "metadata": {},
   "source": [
    "### Q4 — Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786f09fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [\"industry\", \"location\", \"lead_source\", \"employment_status\"]\n",
    "categorical = [c for c in categorical if c in df_train.columns]\n",
    "numerical = [c for c in [\"number_of_courses_viewed\", \"annual_income\", \"interaction_count\", \"lead_score\"] if c in df_train.columns]\n",
    "feature_cols = categorical + numerical\n",
    "\n",
    "baseline_acc, baseline_model, baseline_dv = train_logreg(\n",
    "    df_train, df_val, feature_cols, C=1.0, solver=\"liblinear\", random_state=42\n",
    ")\n",
    "round(baseline_acc, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77e8b9",
   "metadata": {},
   "source": [
    "### Q5 — Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b551a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('employment_status', -0.0034129692832765013),\n",
       " ('industry', 0.0),\n",
       " ('lead_score', 0.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We evaluate removing each candidate feature from the full set and record the accuracy drop\n",
    "candidates = [\"industry\", \"employment_status\", \"lead_score\"]\n",
    "candidates = [c for c in candidates if c in feature_cols]\n",
    "\n",
    "acc_full = baseline_acc  # from Q4\n",
    "drops = {}\n",
    "\n",
    "for feat in candidates:\n",
    "    feats_wo = [f for f in feature_cols if f != feat]\n",
    "    acc_wo, _, _ = train_logreg(df_train, df_val, feats_wo, C=1.0, solver=\"liblinear\", random_state=42)\n",
    "    drops[feat] = acc_full - acc_wo\n",
    "\n",
    "sorted_drops = sorted(drops.items(), key=lambda kv: kv[1])  # smallest difference first\n",
    "sorted_drops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9eba77",
   "metadata": {},
   "source": [
    "### Q6 — Parameter tuning (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9baa6bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.01, 0.734), (0.1, 0.73), (1, 0.73), (10, 0.73), (100, 0.73)], 0.01, 0.734)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = [0.01, 0.1, 1, 10, 100]\n",
    "results = []\n",
    "for C in grid:\n",
    "    acc, _, _ = train_logreg(df_train, df_val, feature_cols, C=C, solver=\"liblinear\", random_state=42)\n",
    "    results.append((C, round(acc, 3)))\n",
    "\n",
    "# Choose the smallest C among the best accuracies\n",
    "best_acc = max(a for _, a in results)\n",
    "best_candidates = [C for C, a in results if a == best_acc]\n",
    "best_C = min(best_candidates)\n",
    "\n",
    "results, best_C, best_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb1774",
   "metadata": {},
   "source": [
    "### Submission — Collect all answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d64bf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': 'retail',\n",
       " 'Q2': 'annual_income and interaction_count',\n",
       " 'Q3': 'lead_source',\n",
       " 'Q4': '0.7303754266211604',\n",
       " 'Q5': \"'employment_status'\",\n",
       " 'Q6': '0.01'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pick_option(value, options):\n",
    "    # For float-like options, compare on formatted strings to desired precision\n",
    "    try:\n",
    "        v = float(value)\n",
    "        # try exact string match after rounding to 2 or 3 decimals depending on options\n",
    "        if any(opt in [\"0.64\",\"0.74\",\"0.84\",\"0.94\"] for opt in options):\n",
    "            vv = f\"{round(v,2):.2f}\"\n",
    "        else:\n",
    "            vv = f\"{v:.3f}\"\n",
    "        for opt in options:\n",
    "            if opt == vv:\n",
    "                return opt\n",
    "    except Exception:\n",
    "        pass\n",
    "    # string mapping (case-insensitive)\n",
    "    s = str(value).strip().lower()\n",
    "    for opt in options:\n",
    "        if str(opt).strip().lower() == s:\n",
    "            return opt\n",
    "    return str(value)\n",
    "\n",
    "# Q1\n",
    "q1_opt = [\"NA\", \"technology\", \"healthcare\", \"retail\"]\n",
    "Q1 = pick_option(df[\"industry\"].mode(dropna=False)[0], q1_opt)\n",
    "\n",
    "# Q2\n",
    "corr_map = {\n",
    "    \"interaction_count & lead_score\": \"interaction_count and lead_score\",\n",
    "    \"number_of_courses_viewed & lead_score\": \"number_of_courses_viewed and lead_score\",\n",
    "    \"number_of_courses_viewed & interaction_count\": \"number_of_courses_viewed and interaction_count\",\n",
    "    \"annual_income & interaction_count\": \"annual_income and interaction_count\"\n",
    "}\n",
    "best_pair = sorted_corrs[0][0]\n",
    "Q2 = corr_map.get(best_pair, best_pair)\n",
    "\n",
    "# Q3\n",
    "Q3 = sorted_mi[0][0]  # already rounded in ranking\n",
    "\n",
    "# Q4\n",
    "Q4 = pick_option(baseline_acc, [\"0.64\", \"0.74\", \"0.84\", \"0.94\"])\n",
    "\n",
    "# Q5\n",
    "Q5_feat = sorted_drops[0][0] if len(sorted_drops) else \"lead_score\"\n",
    "Q5 = f\"'{Q5_feat}'\"\n",
    "\n",
    "# Q6\n",
    "Q6 = pick_option(best_C, [\"0.01\", \"0.1\", \"1\", \"10\", \"100\"])\n",
    "\n",
    "answers = {\"Q1\": Q1, \"Q2\": Q2, \"Q3\": Q3, \"Q4\": Q4, \"Q5\": Q5, \"Q6\": Q6}\n",
    "answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1d9de",
   "metadata": {},
   "source": [
    "### Appendix — Test set score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da320d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7064846416382252"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain on train+val with best C and evaluate on the test set\n",
    "df_tr_full = pd.concat([df_train, df_val], ignore_index=True)\n",
    "acc_full, model_full, dv_full = train_logreg(df_tr_full, df_test, feature_cols, C=best_C, solver=\"liblinear\", random_state=42)\n",
    "acc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92707b11-4c80-4dbc-9b40-711bb088a0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
